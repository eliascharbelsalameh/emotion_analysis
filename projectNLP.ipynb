{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/combined_emotion.csv')\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates(['sentence','emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of the unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['emotion'], color='#539caf', edgecolor='black', bins=len(df['emotion'].unique()))\n",
    "plt.title('Distribution of Emotions', fontsize=16)\n",
    "plt.xlabel('Emotion', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decontraction, Stopwords removal, regex formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\",\n",
    "\"ive\": \"i have\",\n",
    "\"dont\": \"do not\",\n",
    "\"doesnt\": \"does not\",\n",
    "\"cant\": \"cannot\",\n",
    "\"whats\": \"what is\",\n",
    "\"shes\": \"she is\",\n",
    "\"hes\": \"he is\",\n",
    "\"theyre\": \"they are\"\n",
    "}\n",
    "\n",
    "def decontract_words(text):\n",
    "    text = text.split()\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word in contractions:\n",
    "            new_text.append(contractions[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def format_text_regex(text):\n",
    "\n",
    "    # ^https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%.\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%\\+.~#?&\\/=]*)$\n",
    "\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #clean all URLs\n",
    "    text = re.sub(r'\\<a href', ' ', text) #clean html style URL\n",
    "    text = re.sub(r'&amp;', '', text) #remove &amp; chars\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text) #remove special characters\n",
    "    text = re.sub(r'<br />', ' ', text) #remove html style <br>\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    return \" \".join(text)\n",
    "\n",
    "# function that groups logic from other preprocessing functions to clean text\n",
    "def clean_text(text):\n",
    "\n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Use other preprocessing functions\n",
    "    text = decontract_words(text)\n",
    "    text = format_text_regex(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text = remove_stopwords(text)\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['Text_Cleaned'] = list(map(clean_text, df.sentence))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# function to lemmatize words in text cleaned and create a new column lemmatized text and store them there\n",
    "def lemmatized_words(text):\n",
    "    lemm = nltk.stem.WordNetLemmatizer()\n",
    "    df['lemmatized_text'] = list(map(lambda word:\n",
    "                                    list(map(lemm.lemmatize, word)),\n",
    "                                    df.Text_Cleaned))\n",
    "\n",
    "\n",
    "lemmatized_words(df.Text_Cleaned)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "w2v_model = Word2Vec(df['lemmatized_text'], vector_size=300, window=5, min_count=3)\n",
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vec(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(300)  # If no known words, return zero vector\n",
    "    return np.mean(vectors, axis=0)  # Take the mean of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['vector'] = df['lemmatized_text'].apply(lambda x: text_to_vec(x, w2v_model))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df['vector'][0].shape)\n",
    "print(df['vector'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['emotion_label'] = df['emotion'].astype('category').cat.codes\n",
    "y = df['emotion_label'].values  # we use integer labels\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.stack(df['vector'].values),\n",
    "    df['emotion_label'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True) # shuffle the data and batching it to reduce the amount of data to be loaded into the gpu's memory\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, model_type, dropout_rate):\n",
    "        super(SequenceModel, self).__init__()\n",
    "        self.model_type = model_type.lower()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate  # Dropout probability\n",
    "        \n",
    "        # Define the recurrent layer\n",
    "        if self.model_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        elif self.model_type == \"lstm\":\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        elif self.model_type == \"gru\":\n",
    "            self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose from ['RNN', 'LSTM', 'GRU'].\")\n",
    "\n",
    "        # Dropout before the final fully connected layer\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Adding a sequence length dimension (batch_size, seq_len=1, input_size)\n",
    "\n",
    "        # Pass through RNN/LSTM/GRU\n",
    "        if self.model_type == \"rnn\":\n",
    "            out, _ = self.rnn(x)\n",
    "        elif self.model_type == \"lstm\":\n",
    "            out, _ = self.lstm(x)\n",
    "        elif self.model_type == \"gru\":\n",
    "            out, _ = self.gru(x)\n",
    "\n",
    "        out = self.dropout(out[:, -1, :])  # Apply dropout before the FC layer\n",
    "        out = self.fc(out)  # Fully connected layer\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_sequence_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(accuracy)\n",
    "\n",
    "        # Evaluate on the test set at the end of the epoch\n",
    "        test_loss, test_accuracy, _, _ = evaluate_sequence_model(model, test_loader, criterion)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        model.train() # Switch back to training mode after evaluation\n",
    "\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_loss:.4f}, Train Acc: {accuracy:.4f}, \"\n",
    "                f\"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}, LR: {current_lr:.6f}\")\n",
    "\n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies\n",
    "\n",
    "def evaluate_sequence_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)  # Single forward pass\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Store results for confusion matrix\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return avg_loss, accuracy, all_preds, all_labels\n",
    "\n",
    "def plot_training_results_combined(train_losses, train_accuracies, test_losses, test_accuracies, model_name):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Loss Plot\n",
    "    axes[0].plot(epochs, train_losses, label=\"Train Loss\", color=\"blue\", linestyle=\"-\")\n",
    "    axes[0].plot(epochs, test_losses, label=\"Test Loss\", color=\"red\", linestyle=\"--\")\n",
    "    axes[0].set_title(f\"{model_name} - Loss Over Epochs\")\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Accuracy Plot\n",
    "    axes[1].plot(epochs, train_accuracies, label=\"Train Accuracy\", color=\"green\", linestyle=\"-\")\n",
    "    axes[1].plot(epochs, test_accuracies, label=\"Test Accuracy\", color=\"orange\", linestyle=\"--\")\n",
    "    axes[1].set_title(f\"{model_name} - Accuracy Over Epochs\")\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(all_preds, all_labels, class_names):\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print classification report for detailed metrics\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "def get_classification_metrics(all_preds, all_labels, class_names):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "def evaluate_and_plot_results(model, test_loader, class_names, criterion, epochs):\n",
    "    # Evaluate once to get loss, accuracy, predictions, and labels\n",
    "    test_loss, test_accuracy, all_preds, all_labels = evaluate_sequence_model(model, test_loader, criterion)\n",
    "\n",
    "    # Expand test loss & accuracy across epochs to match x-axis\n",
    "    test_losses = [test_loss] * epochs\n",
    "    test_accuracies = [test_accuracy] * epochs\n",
    "\n",
    "    # Plot confusion matrix using collected predictions\n",
    "    plot_confusion_matrix(all_preds, all_labels, class_names)\n",
    "    get_classification_metrics(all_preds, all_labels, class_names)\n",
    "\n",
    "    return test_losses, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, file_path): # =\"model_checkpoint.pth\"\n",
    "    \"\"\"\n",
    "    Save the model state dictionary and optimizer state.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "        epoch (int): The last epoch the model was trained on.\n",
    "        file_path (str): Path to save the model file.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"‚úÖ Model saved successfully at: {file_path}\")\n",
    "\n",
    "def load_model(model, optimizer, file_path):\n",
    "    \"\"\"\n",
    "    Load the model state dictionary and optimizer state.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to load weights into.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to load state.\n",
    "        file_path (str): Path of the saved model file.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): Model with loaded weights.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer with loaded state.\n",
    "        epoch (int): The epoch at which the model was saved.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(file_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "    print(f\"‚úÖ Model loaded successfully from: {file_path} (Epoch {epoch})\")\n",
    "    return model, optimizer, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(df['emotion'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model type: 'rnn', 'lstm', or 'gru'\n",
    "model_type = \"lstm\"  # \"rnn\" / \"gru\" / \"lstm\"\n",
    "\n",
    "# Hyperparameters (adjust as needed)\n",
    "input_size = 300  # Matches Word2Vec vector size\n",
    "hidden_size = 128  # Number of neurons in hidden layers\n",
    "num_layers = 2  # Number of RNN/LSTM/GRU layers\n",
    "output_size = 6  # Number of emotion classes\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# Initialize model\n",
    "model = SequenceModel(input_size, hidden_size, output_size, num_layers, model_type, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "train_losses, train_accuracies, test_losses, test_accuracies = train_sequence_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer, scheduler, epochs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "save_model(model, optimizer, epoch=epochs, file_path=\"lstm_newest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plot_training_results_combined(train_losses, train_accuracies, test_losses, test_accuracies, model_name=model_type.upper())\n",
    "evaluate_and_plot_results(model, test_loader, class_names, criterion, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model, optimizer, last_epoch = load_model(model, optimizer, file_path=\"lstm_newest.pth\")\n",
    "# plot_training_results_combined(train_losses, train_accuracies, test_losses, test_accuracies, model_name=model_type.upper())\n",
    "evaluate_and_plot_results(model, test_loader, class_names, criterion, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "validation_data = {\n",
    "    \"sentence\": [\n",
    "        # Joy\n",
    "        \"I am so happy to see you!\",\n",
    "        \"This is the best day of my life!\",\n",
    "        \"I can't stop smiling right now!\",\n",
    "        \n",
    "        # Sadness\n",
    "        \"I feel so alone today...\",\n",
    "        \"Nothing ever goes right for me.\",\n",
    "        \"My heart is heavy with sorrow.\",\n",
    "\n",
    "        # Fear\n",
    "        \"I am scared to be alone at night.\",\n",
    "        \"Something doesn't feel right about this.\",\n",
    "        \"I have a bad feeling about this situation.\",\n",
    "\n",
    "        # Love\n",
    "        \"I love spending time with you!\",\n",
    "        \"You mean the world to me.\",\n",
    "        \"Every moment with you is special.\",\n",
    "\n",
    "        # Anger\n",
    "        \"This makes me so mad!\",\n",
    "        \"I can't believe they did this to me!\",\n",
    "        \"I'm absolutely furious right now!\",\n",
    "\n",
    "        # Surprise\n",
    "        \"Wow, I didn't expect this at all!\",\n",
    "        \"I can't believe what just happened!\",\n",
    "        \"That was completely unexpected!\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "new_validation_df = pd.DataFrame(validation_data)\n",
    "\n",
    "# Save to CSV (Optional)\n",
    "new_validation_df.to_csv(\"new_validation_data.csv\", index=False)\n",
    "\n",
    "print(new_validation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load new validation data (replace 'new_validation.csv' with your actual file)\n",
    "new_df = pd.read_csv(\"new_validation_data.csv\")  # Ensure it has a 'sentence' column\n",
    "print(new_df.head())\n",
    "\n",
    "# Step 1: Preprocessing - Apply the same text cleaning and vectorization\n",
    "new_df['Text_Cleaned'] = new_df['sentence'].apply(clean_text)\n",
    "new_df['lemmatized_text'] = new_df['Text_Cleaned'].apply(lambda x: [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in x])\n",
    "\n",
    "# Convert text to vectors using Word2Vec (Ensure you're using the trained model)\n",
    "new_df['vector'] = new_df['lemmatized_text'].apply(lambda x: text_to_vec(x, w2v_model))\n",
    "\n",
    "# Step 2: Convert to PyTorch Dataset\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(np.stack(X), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "# Prepare validation DataLoader\n",
    "validation_dataset = ValidationDataset(new_df['vector'].values)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Step 3: Evaluate on Validation Set\n",
    "def evaluate_validation_data(model, validation_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in validation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            preds = torch.argmax(outputs, dim=1)  # Get class predictions\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Run evaluation\n",
    "predictions = evaluate_validation_data(model, validation_loader)\n",
    "\n",
    "# Map predictions back to labels\n",
    "new_df['predicted_label'] = predictions\n",
    "new_df['predicted_emotion'] = new_df['predicted_label'].map(lambda x: class_names[x])  # Map numerical labels to class names\n",
    "\n",
    "print(new_df[['sentence', 'predicted_emotion']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **clear the GPU memory** in your **CMD prompt (Windows)**, use one of the following methods:\n",
    "\n",
    "---\n",
    "\n",
    "### **1Ô∏è‚É£ Using `torch.cuda.empty_cache()` (Recommended)**\n",
    "This **frees up unused GPU memory** inside your Python script (won't restart the CUDA driver).\n",
    "\n",
    "‚úÖ **Run inside your Python script or Jupyter Notebook:**\n",
    "```python\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Restart Python Kernel (Jupyter Notebook)**\n",
    "If using **Jupyter Notebook**, restart the kernel to free all memory:\n",
    "```python\n",
    "import os\n",
    "os._exit(00)\n",
    "```\n",
    "or simply:\n",
    "- Click **Kernel** > **Restart Kernel** in Jupyter Notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### **3Ô∏è‚É£ Use `nvidia-smi` in CMD (Windows)**\n",
    "This **kills all GPU processes**, **freeing up memory**.\n",
    "\n",
    "‚úÖ **Run in CMD Prompt:**\n",
    "```cmd\n",
    "nvidia-smi\n",
    "```\n",
    "This shows GPU memory usage.\n",
    "\n",
    "To **clear the GPU memory completely**, **force-kill all CUDA processes**:\n",
    "```cmd\n",
    "nvidia-smi --gpu-reset\n",
    "```\n",
    "üî¥ **‚ö† WARNING:** This will **reset the entire GPU driver**, affecting running tasks.\n",
    "\n",
    "For a **safer approach**, **kill only a specific process (PID)**:\n",
    "1. Run:\n",
    "   ```cmd\n",
    "   nvidia-smi\n",
    "   ```\n",
    "   - Find the **Process ID (PID)** of the process consuming memory.\n",
    "2. Kill the process:\n",
    "   ```cmd\n",
    "   taskkill /PID <process_id> /F\n",
    "   ```\n",
    "   Example:\n",
    "   ```cmd\n",
    "   taskkill /PID 12345 /F\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4Ô∏è‚É£ Restart the CUDA Driver (Last Resort)**\n",
    "If all else fails, **restart the NVIDIA driver**.\n",
    "\n",
    "‚úÖ **Run in CMD Prompt (Admin Mode)**:\n",
    "```cmd\n",
    "net stop nvlddmkm\n",
    "net start nvlddmkm\n",
    "```\n",
    "üî¥ **‚ö† WARNING:** This will **temporarily disable your display** while the driver restarts.\n",
    "\n",
    "---\n",
    "\n",
    "### **‚úÖ Summary**\n",
    "| **Method** | **Effect** | **When to Use?** |\n",
    "|------------|-----------|------------------|\n",
    "| `torch.cuda.empty_cache()` | Frees **unused memory** | Use inside Python when running models. |\n",
    "| Restart Python Kernel | Clears **all memory** | If `empty_cache()` isn't enough. |\n",
    "| `nvidia-smi --gpu-reset` | Resets **all CUDA processes** | If memory is still occupied. |\n",
    "| Kill Specific PID (`taskkill`) | Frees memory from **one process** | If you want to free memory selectively. |\n",
    "| Restart CUDA Driver | **Resets entire GPU** | **Last resort**, may cause flickering. |\n",
    "\n",
    "üöÄ **Try `torch.cuda.empty_cache()` first, and escalate if needed!** Let me know if you need more help! üí°"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
